"""
AI é¢„æµ‹é¡µé¢ - Phase 5e
æ”¯æŒæœºå™¨å­¦ä¹ é¢„æµ‹å’Œæ¨¡å‹ç»“æœè§£é‡Š
"""

import streamlit as st
import requests
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import datetime

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI é¢„æµ‹ | GeologAI",
    page_icon="ğŸ¤–",
    layout="wide"
)

# API é…ç½®
API_BASE_URL = "http://127.0.0.1:8001"
PREDICTIONS_ENDPOINT = f"{API_BASE_URL}/api/v1/predictions"
DATA_ENDPOINT = f"{API_BASE_URL}/api/v1/data"
PROJECTS_ENDPOINT = f"{API_BASE_URL}/api/v1/projects"
MODELS_ENDPOINT = f"{API_BASE_URL}/api/v1/models"

# éªŒè¯è®¤è¯
if not st.session_state.get("auth_token"):
    st.error("âŒ è¯·å…ˆç™»å½•")
    st.stop()

# é¡µé¢æ ‡é¢˜
st.title("ğŸ¤– AI é¢„æµ‹åˆ†æ")
st.markdown("---")

# è·å–è®¤è¯å¤´
headers = {
    "Authorization": f"Bearer {st.session_state.auth_token}",
    "Content-Type": "application/json"
}

# ======================== è¾…åŠ©å‡½æ•° ========================
@st.cache_data(ttl=30)
def get_projects():
    """è·å–é¡¹ç›®åˆ—è¡¨"""
    try:
        response = requests.get(
            PROJECTS_ENDPOINT,
            headers=headers,
            timeout=10
        )
        if response.status_code == 200:
            projects = response.json()
            return {p.get("id"): p.get("name") for p in projects}
        return {}
    except:
        return {}

@st.cache_data(ttl=30)
def get_data_list(project_id):
    """è·å–é¡¹ç›®ä¸‹çš„æ•°æ®åˆ—è¡¨"""
    try:
        response = requests.get(
            f"{DATA_ENDPOINT}?project_id={project_id}",
            headers=headers,
            timeout=10
        )
        if response.status_code == 200:
            return response.json()
        return []
    except:
        return []

@st.cache_data(ttl=60)
def get_models():
    """è·å–å¯ç”¨çš„é¢„æµ‹æ¨¡å‹"""
    try:
        response = requests.get(
            MODELS_ENDPOINT,
            headers=headers,
            timeout=10
        )
        if response.status_code == 200:
            return response.json()
        # è¿”å›é»˜è®¤æ¨¡å‹åˆ—è¡¨
        return [
            {"id": "model_1", "name": "éšæœºæ£®æ—æ¨¡å‹", "type": "regression", "accuracy": 0.87},
            {"id": "model_2", "name": "ç¥ç»ç½‘ç»œæ¨¡å‹", "type": "classification", "accuracy": 0.92},
            {"id": "model_3", "name": "æ”¯æŒå‘é‡æœº", "type": "regression", "accuracy": 0.85}
        ]
    except:
        return []

@st.cache_data(ttl=60)
def get_data_content(data_id):
    """è·å–æ•°æ®è¯¦ç»†å†…å®¹"""
    try:
        response = requests.get(
            f"{DATA_ENDPOINT}/{data_id}",
            headers=headers,
            timeout=30
        )
        if response.status_code == 200:
            return response.json()
        return None
    except:
        return None

# ======================== ä¾§è¾¹æ é…ç½® ========================
with st.sidebar:
    st.subheader("âš™ï¸ é¢„æµ‹é…ç½®")
    
    # é€‰æ‹©é¡¹ç›®
    projects_dict = get_projects()
    if not projects_dict:
        st.warning("âš ï¸ è¯·å…ˆåˆ›å»ºé¡¹ç›®")
        st.stop()
    
    project_id = st.selectbox(
        "é€‰æ‹©é¡¹ç›®",
        list(projects_dict.keys()),
        format_func=lambda x: projects_dict[x]
    )
    
    # è·å–æ•°æ®åˆ—è¡¨
    data_list = get_data_list(project_id)
    if not data_list:
        st.warning("ğŸ’¡ è¯¥é¡¹ç›®æš‚æ— æ•°æ®")
        st.stop()
    
    # é€‰æ‹©æ•°æ®
    data_names = {i: d.get("well_name") for i, d in enumerate(data_list)}
    selected_data_idx = st.selectbox(
        "é€‰æ‹©äº•å·",
        list(data_names.keys()),
        format_func=lambda x: data_names[x]
    )
    
    selected_data = data_list[selected_data_idx]
    data_id = selected_data.get("id")
    
    st.markdown("---")
    
    # é€‰æ‹©æ¨¡å‹
    models = get_models()
    model_names = {m.get("id"): m.get("name") for m in models}
    
    selected_model_id = st.selectbox(
        "é€‰æ‹©é¢„æµ‹æ¨¡å‹",
        list(model_names.keys()),
        format_func=lambda x: model_names[x]
    )
    
    st.markdown("---")
    
    # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
    st.subheader("ğŸ“Š æ•°æ®ä¿¡æ¯")
    st.metric("äº•å·", selected_data.get("well_name"))
    st.metric("è¡Œæ•°", selected_data.get("rows_count", 0))

# ======================== ä¸»å†…å®¹åŒº ========================
# åŠ è½½æ•°æ®
data_content = get_data_content(data_id)

if not data_content:
    st.error("âŒ æ— æ³•åŠ è½½æ•°æ®")
    st.stop()

# è½¬æ¢ä¸º DataFrame
try:
    if isinstance(data_content.get("data"), list):
        df = pd.DataFrame(data_content["data"])
    else:
        st.error("âŒ æ•°æ®æ ¼å¼é”™è¯¯")
        st.stop()
except Exception as e:
    st.error(f"âŒ æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
    st.stop()

numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()

# ======================== é¢„æµ‹é…ç½® ========================
st.subheader("ğŸ”§ é¢„æµ‹å‚æ•°é…ç½®")

col1, col2, col3 = st.columns(3)

with col1:
    if numeric_columns:
        target_column = st.selectbox(
            "é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆé¢„æµ‹ç›®æ ‡ï¼‰",
            numeric_columns
        )
    else:
        st.error("âŒ æš‚æ— æ•°å€¼å‹åˆ—")
        st.stop()

with col2:
    # ç§»é™¤ç›®æ ‡åˆ—åçš„ç‰¹å¾
    feature_columns = [col for col in numeric_columns if col != target_column]
    selected_features = st.multiselect(
        "é€‰æ‹©ç‰¹å¾å˜é‡",
        feature_columns,
        default=feature_columns[:min(5, len(feature_columns))]
    )

with col3:
    train_test_split = st.slider(
        "è®­ç»ƒé›†æ¯”ä¾‹",
        0.5,
        0.95,
        0.8,
        0.05
    )

# é¢„æµ‹å‚æ•°
st.markdown("---")
st.subheader("ğŸ“Š æ¨¡å‹å‚æ•°")

col1, col2, col3 = st.columns(3)

with col1:
    cross_validation = st.checkbox("å¯ç”¨äº¤å‰éªŒè¯", value=True)

with col2:
    random_state = st.number_input(
        "éšæœºç§å­",
        min_value=0,
        max_value=9999,
        value=42,
        step=1
    )

with col3:
    if cross_validation:
        cv_folds = st.number_input(
            "äº¤å‰éªŒè¯æŠ˜æ•°",
            min_value=2,
            max_value=10,
            value=5
        )

# ======================== æ‰§è¡Œé¢„æµ‹ ========================
st.markdown("---")

col1, col2, col3 = st.columns([1, 1, 1])

with col1:
    execute_prediction = st.button("ğŸš€ æ‰§è¡Œé¢„æµ‹", use_container_width=True)

with col2:
    reset_button = st.button("ğŸ”„ é‡ç½®", use_container_width=True)

with col3:
    help_button = st.button("â“ å¸®åŠ©", use_container_width=True)

if help_button:
    st.info("""
    **AI é¢„æµ‹è¯´æ˜ï¼š**
    
    1. **é€‰æ‹©ç›®æ ‡å˜é‡** - è¦é¢„æµ‹çš„æ•°å€¼åˆ—
    2. **é€‰æ‹©ç‰¹å¾å˜é‡** - ç”¨äºé¢„æµ‹çš„è¾“å…¥åˆ—
    3. **è°ƒæ•´å‚æ•°** - é€‰æ‹©æ¨¡å‹å‚æ•°å’Œè®­ç»ƒé…ç½®
    4. **æ‰§è¡Œé¢„æµ‹** - è¿è¡Œé¢„æµ‹æ¨¡å‹
    
    **å‚æ•°è¯´æ˜ï¼š**
    - **è®­ç»ƒé›†æ¯”ä¾‹** - ç”¨äºè®­ç»ƒçš„æ•°æ®å æ¯”ï¼ˆå‰©ä½™ç”¨äºæµ‹è¯•ï¼‰
    - **äº¤å‰éªŒè¯** - å¯ç”¨æ—¶ä½¿ç”¨KæŠ˜éªŒè¯æé«˜æ¨¡å‹ç¨³å¥æ€§
    - **éšæœºç§å­** - ç”¨äºé‡ç°ç»“æœçš„éšæœºæ•°ç§å­
    """)

if reset_button:
    st.session_state.pop("prediction_result", None)
    st.rerun()

if execute_prediction:
    if not selected_features:
        st.error("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡")
    else:
        with st.spinner("ğŸ”„ æ­£åœ¨æ‰§è¡Œé¢„æµ‹..."):
            try:
                # å‡†å¤‡é¢„æµ‹è¯·æ±‚
                prediction_request = {
                    "data_id": str(data_id),
                    "model_id": selected_model_id,
                    "target_column": target_column,
                    "feature_columns": selected_features,
                    "train_test_split": train_test_split,
                    "cross_validation": cross_validation,
                    "cv_folds": cv_folds if cross_validation else None,
                    "random_state": random_state
                }
                
                # å‘é€é¢„æµ‹è¯·æ±‚
                response = requests.post(
                    PREDICTIONS_ENDPOINT,
                    json=prediction_request,
                    headers=headers,
                    timeout=60
                )
                
                if response.status_code == 200 or response.status_code == 201:
                    result = response.json()
                    st.session_state.prediction_result = result
                    st.success("âœ… é¢„æµ‹å®Œæˆï¼")
                else:
                    error_msg = response.json().get("detail", "æœªçŸ¥é”™è¯¯")
                    st.error(f"âŒ é¢„æµ‹å¤±è´¥: {error_msg}")
            
            except requests.exceptions.Timeout:
                st.error("âŒ é¢„æµ‹è¶…æ—¶ï¼Œè¯·å°è¯•å‡å°‘æ•°æ®é‡æˆ–ç®€åŒ–æ¨¡å‹")
            except requests.exceptions.ConnectionError:
                st.error("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨")
            except Exception as e:
                st.error(f"âŒ é”™è¯¯: {str(e)}")

# ======================== æ˜¾ç¤ºé¢„æµ‹ç»“æœ ========================
if "prediction_result" in st.session_state and st.session_state.prediction_result:
    result = st.session_state.prediction_result
    
    st.markdown("---")
    st.subheader("ğŸ“ˆ é¢„æµ‹ç»“æœ")
    
    # æ˜¾ç¤ºæ¨¡å‹æ€§èƒ½æŒ‡æ ‡
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "æ¨¡å‹ç²¾åº¦",
            f"{result.get('accuracy', 0):.3f}",
            delta=f"{(result.get('accuracy', 0) - 0.5) * 100:.1f}%"
        )
    
    with col2:
        st.metric("RÂ² åˆ†æ•°", f"{result.get('r2_score', 0):.3f}")
    
    with col3:
        st.metric("MAE", f"{result.get('mae', 0):.3f}")
    
    with col4:
        st.metric("RMSE", f"{result.get('rmse', 0):.3f}")
    
    st.markdown("---")
    
    # æ˜¾ç¤ºé¢„æµ‹å€¼ vs å®é™…å€¼
    col1, col2 = st.columns(2)
    
    with col1:
        # é¢„æµ‹å€¼ vs å®é™…å€¼æ•£ç‚¹å›¾
        predictions = result.get("predictions", [])
        actual_values = result.get("actual_values", [])
        
        if predictions and actual_values:
            fig = go.Figure()
            
            fig.add_trace(go.Scatter(
                x=actual_values,
                y=predictions,
                mode='markers',
                marker=dict(size=8, opacity=0.6),
                name="é¢„æµ‹ç»“æœ"
            ))
            
            # æ·»åŠ å®Œç¾é¢„æµ‹çº¿
            min_val = min(min(actual_values), min(predictions))
            max_val = max(max(actual_values), max(predictions))
            fig.add_trace(go.Scatter(
                x=[min_val, max_val],
                y=[min_val, max_val],
                mode='lines',
                name="å®Œç¾é¢„æµ‹",
                line=dict(dash='dash', color='red')
            ))
            
            fig.update_layout(
                title="é¢„æµ‹å€¼ vs å®é™…å€¼",
                xaxis_title="å®é™…å€¼",
                yaxis_title="é¢„æµ‹å€¼",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # æ®‹å·®åˆ†å¸ƒ
        if predictions and actual_values:
            residuals = np.array(actual_values) - np.array(predictions)
            
            fig = go.Figure(data=[
                go.Histogram(
                    x=residuals,
                    nbinsx=30,
                    name="æ®‹å·®",
                    hovertemplate="<b>%{x:.2f}</b><br>é¢‘æ•°: %{y}<extra></extra>"
                )
            ])
            
            fig.update_layout(
                title="æ®‹å·®åˆ†å¸ƒ",
                xaxis_title="æ®‹å·®å€¼",
                yaxis_title="é¢‘æ•°",
                height=400
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # ç‰¹å¾é‡è¦æ€§
    st.markdown("---")
    st.subheader("ğŸ¯ ç‰¹å¾é‡è¦æ€§")
    
    feature_importance = result.get("feature_importance", {})
    
    if feature_importance:
        # æ’åºç‰¹å¾é‡è¦æ€§
        sorted_features = sorted(
            feature_importance.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        fig = go.Figure(data=[
            go.Bar(
                x=[f[1] for f in sorted_features],
                y=[f[0] for f in sorted_features],
                orientation='h',
                marker=dict(color=[f[1] for f in sorted_features], colorscale='Viridis')
            )
        ])
        
        fig.update_layout(
            title="ç‰¹å¾é‡è¦æ€§æ’å",
            xaxis_title="é‡è¦æ€§å¾—åˆ†",
            height=300,
            margin=dict(l=150)
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    # é¢„æµ‹ç»“æœè¡¨æ ¼
    st.markdown("---")
    st.subheader("ğŸ“‹ é¢„æµ‹è¯¦æƒ…")
    
    if predictions and actual_values:
        results_df = pd.DataFrame({
            "æ ·æœ¬ç´¢å¼•": range(len(predictions)),
            "å®é™…å€¼": actual_values,
            "é¢„æµ‹å€¼": predictions,
            "è¯¯å·®": np.array(actual_values) - np.array(predictions),
            "ç›¸å¯¹è¯¯å·®%": (abs(np.array(actual_values) - np.array(predictions)) / 
                        (abs(np.array(actual_values)) + 1e-10) * 100).round(2)
        })
        
        st.dataframe(
            results_df.head(50),
            use_container_width=True,
            hide_index=False
        )
        
        # ä¸‹è½½ç»“æœ
        csv = results_df.to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ",
            data=csv,
            file_name=f"prediction_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )

# ======================== é¡µè„š ========================
st.markdown("---")
col1, col2, col3 = st.columns(3)
with col1:
    if st.button("ğŸ“ˆ åˆ†ææ›²çº¿", use_container_width=True):
        st.switch_page("pages/04_analysis.py")
with col2:
    if st.button("ğŸ“ æ¨¡å‹è®­ç»ƒ", use_container_width=True):
        st.switch_page("pages/06_model_training.py")
with col3:
    if st.button("ğŸ”„ åˆ·æ–°", use_container_width=True):
        st.cache_data.clear()
        st.rerun()
